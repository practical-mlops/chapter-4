{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from plotnine import ggplot,geom_bar,theme_bw,labs,coord_flip,aes\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('../data/income_data.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head() ,'\\n') \n",
    "print(df.info(), '\\n')    \n",
    "print(df.describe(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"categorical_variable_plots\"):\n",
    "    os.makedirs(\"categorical_variable_plots\")    \n",
    "for i in df.iloc[:,:-1].select_dtypes(include='object').columns:\n",
    "    print(f'Variable {i}  \\n ')\n",
    "    print(df[i].value_counts())\n",
    "    plot = ggplot(df)+ geom_bar(aes(x=df[i], fill=df.Target), position='fill')+ theme_bw() + labs(title=f'Variable {i} ~ Target')+ coord_flip()\n",
    "    print(plot)    #A\n",
    "    plot.save(f\"categorical_variable_plots/Variable {i}\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up MLflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting tracking uri and experiment. If experiment name does not exist it will be created\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"income-classifier\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=f\"eda-{uuid.uuid4()}\"): \n",
    "    for i in df.iloc[:,:-1].select_dtypes(include='object').columns:\n",
    "        print(f'Variable {i}  \\n ')\n",
    "        print(df[i].value_counts())\n",
    "\n",
    "        plot = ggplot(df)+ geom_bar(aes(x=df[i], fill=df.Target), position='fill')+ theme_bw() + labs(title=f'Variable {i} ~ Target')+ coord_flip()\n",
    "        print(plot)\n",
    "        if not os.path.exists(\"categorical_variable_plots\"):\n",
    "            os.makedirs(\"categorical_variable_plots\")\n",
    "        plot.save(f\"categorical_variable_plots/Variable {i}\")\n",
    "        mlflow.log_artifacts(\"categorical_variable_plots\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "target=df.Target\n",
    "feature_df=df.drop('Target', axis=1)\n",
    "#Codifying the predictors and the target\n",
    "encoder=OneHotEncoder(sparse_output=False, drop='if_binary')\n",
    "target=encoder.fit_transform(np.array(target).reshape(-1,1))\n",
    "dummyfied_df=pd.get_dummies(feature_df, drop_first=True, sparse=False, dtype=float)\n",
    "col_list = dummyfied_df.columns.to_list()\n",
    "X_train,X_test,y_train, y_test=train_test_split(dummyfied_df.reindex(columns=col_list,fill_value=0)\n",
    ", target, train_size=0.80, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minio import Minio\n",
    "minioClient = Minio(\"localhost:9000\", access_key=\"minio\", secret_key=\"minio123\", secure=False)\n",
    "found = minioClient.bucket_exists(\"mlflow-datasets\")\n",
    "if not found:\n",
    "    print(\"PLEASE CREATE BUCKET IN MINIO BEFORE PROCEEDING\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "def save_df_to_minio(df,bucket_name,path):\n",
    "    csv_bytes = df.to_csv(index=False).encode('utf-8')\n",
    "    csv_buffer = BytesIO(csv_bytes)\n",
    "\n",
    "    minioClient.put_object(f'{bucket_name}',\n",
    "                        f'{path}',\n",
    "                            data=csv_buffer,\n",
    "                            length=len(csv_bytes),\n",
    "                            content_type='application/csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with MLflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import  roc_auc_score\n",
    "BUCKET_NAME = \"mlflow-datasets\"\n",
    "with mlflow.start_run() as run:\n",
    "    results=pd.DataFrame(index=['Roc Auc Score test', 'Accuracy score train', 'Accuracy Score test','time to fit'])\n",
    "    tree=DecisionTreeClassifier()\n",
    "    run_id = run.info.run_id\n",
    "    feature_df_path = f\"income-classifier-datasets/feature_df-{run_id}.csv\"\n",
    "    save_df_to_minio(feature_df,BUCKET_NAME,feature_df_path)\n",
    "    train_df = pd.concat([X_train,pd.Series(y_train.ravel())],axis=1)\n",
    "    train_df_path = f\"income-classifier-datasets/train-{run_id}.csv\"\n",
    "    save_df_to_minio(train_df,BUCKET_NAME,train_df_path)    #A\n",
    "    test_df = pd.concat([X_test,pd.Series(y_test.ravel())],axis=1)\n",
    "    test_df_path = f\"income-classifier-datasets/test-{run_id}.csv\"\n",
    "    save_df_to_minio(test_df,BUCKET_NAME,test_df_path)    \n",
    "    training_dataset = mlflow.data.from_pandas(train_df, source=f\"{BUCKET_NAME}/{train_df_path}\")    #B\n",
    "    test_dataset = mlflow.data.from_pandas(test_df, source=f\"{BUCKET_NAME}/{test_df_path}\")\n",
    "    feature_dataset = mlflow.data.from_pandas(feature_df, source=f\"{BUCKET_NAME}/{feature_df_path}\")   \n",
    "    mlflow.log_input(training_dataset,context=\"training\")    #C\n",
    "    mlflow.log_input(test_dataset,context=\"testing\")\n",
    "    mlflow.log_input(feature_dataset,context=\"reference\")    \n",
    "    tree.fit(X_train, y_train.ravel())    #D\n",
    "    roc_auc_score_train = roc_auc_score(y_train==1, tree.predict_proba(X_train)[:,1])    #E\n",
    "    roc_auc_score_test = roc_auc_score(y_test==1, tree.predict_proba(X_test)[:,1])\n",
    "    training_accuracy = tree.score(X_train, y_train)\n",
    "    test_accuracy = tree.score(X_test, y_test)\n",
    "    mlflow.log_metric(\"roc_auc_score_train\",roc_auc_score_train)    #F\n",
    "    print(f'Roc Auc Score train: {roc_auc_score_train}  \\n')\n",
    "    mlflow.log_metric(\"roc_auc_score_test\",roc_auc_score_test)\n",
    "    print(f'Roc Auc Score test: {roc_auc_score_test}  \\n')\n",
    "    mlflow.log_metric(\"training_accuracy\",training_accuracy)\n",
    "    print(f'Accuracy train : {training_accuracy}')\n",
    "    mlflow.log_metric(\"test_accuracy\",test_accuracy)\n",
    "    print(f'Accuracy test : {test_accuracy}')\n",
    "    mlflow.sklearn.log_model(tree,\"income-classifier\")    #G\n",
    "    mlflow.log_params(tree.get_params())    #H\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "with mlflow.start_run():\n",
    "    forest=RandomForestClassifier()\n",
    "\n",
    "    start=time.time()\n",
    "    train_df = pd.concat([X_train,pd.Series(y_train.ravel())],axis=1)\n",
    "    test_df = pd.concat([X_test,pd.Series(y_test.ravel())],axis=1)\n",
    "    feature_df_path = f\"income-classifier-datasets/feature_df-{run_id}.csv\"\n",
    "    train_df_path = f\"income-classifier-datasets/train-{run_id}.csv\"\n",
    "    save_df_to_minio(train_df,BUCKET_NAME,train_df_path)\n",
    "    save_df_to_minio(feature_df,BUCKET_NAME,feature_df_path)\n",
    "    test_df_path = f\"income-classifier-datasets/test-{run_id}.csv\"\n",
    "    test_df_path = f\"income-classifier-datasets/test-{run_id}.csv\"\n",
    "    save_df_to_minio(test_df,BUCKET_NAME,test_df_path)\n",
    "    feature_dataset = mlflow.data.from_pandas(feature_df, source=f\"{BUCKET_NAME}/{test_df_path}\")\n",
    "    training_dataset = mlflow.data.from_pandas(train_df, source=f\"{BUCKET_NAME}/{train_df_path}\")\n",
    "    test_dataset = mlflow.data.from_pandas(test_df, source=f\"{BUCKET_NAME}/{test_df_path}\")\n",
    "    mlflow.log_input(training_dataset,context=\"training\")\n",
    "    mlflow.log_input(test_dataset,context=\"testing\")\n",
    "    mlflow.log_input(feature_dataset,context=\"reference_features\")\n",
    "    forest.fit(X_train, y_train.ravel())\n",
    "    end=time.time()\n",
    "\n",
    "    roc_auc_score_train = roc_auc_score(y_train==1, forest.predict_proba(X_train)[:,1])\n",
    "    roc_auc_score_test = roc_auc_score(y_test==1, forest.predict_proba(X_test)[:,1])\n",
    "    training_accuracy = forest.score(X_train, y_train)\n",
    "    test_accuracy = forest.score(X_test, y_test)\n",
    "\n",
    "    mlflow.log_metric(\"roc_auc_score_train\",roc_auc_score_train)\n",
    "    print(f'Roc Auc Score train: {roc_auc_score_train}  \\n')\n",
    "    mlflow.log_metric(\"roc_auc_score_test\",roc_auc_score_test)\n",
    "    print(f'Roc Auc Score test: {roc_auc_score_test}  \\n')\n",
    "    mlflow.log_metric(\"training_accuracy\",training_accuracy)\n",
    "    print(f'Accuracy train : {training_accuracy}')\n",
    "    mlflow.log_metric(\"test_accuracy\",test_accuracy)\n",
    "    print(f'Accuracy test : {test_accuracy}')\n",
    "    mlflow.sklearn.log_model(forest,\"income-classifier\")\n",
    "    \n",
    "    mlflow.log_params(forest.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost with MLflow autologging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import  accuracy_score\n",
    "with mlflow.start_run():\n",
    "    mlflow.xgboost.autolog()    #A\n",
    "    n_round=30\n",
    "    dtrain= xgb.DMatrix(data=X_train, label=y_train.ravel())\n",
    "    dtest= xgb.DMatrix(data=X_test, label=y_test.ravel())\n",
    "    params={\"objective\":\"binary:logistic\",'colsample_bytree': 1,'learning_rate': 1,\n",
    "                    'max_depth': 10 , 'subsample':1}\n",
    "    model=xgb.train(params,dtrain, n_round)\n",
    "    ax = xgb.plot_importance(model, max_num_features=10, importance_type='cover')\n",
    "    fig = ax.figure\n",
    "    fig.set_size_inches(10, 8)\n",
    "    pred_train= model.predict(dtrain)\n",
    "    pred_test=model.predict(dtest)\n",
    "    model=xgb.train(params={\"objective\":\"binary:hinge\",'colsample_bytree': 1,'learning_rate': 1,\n",
    "                    'max_depth': 10 , 'subsample':1}, dtrain=dtrain)\n",
    "    pred_train= model.predict(dtrain)\n",
    "    pred_test=model.predict(dtest)\n",
    "    roc_auc_score_train = roc_auc_score(y_train==1, pred_train)\n",
    "    roc_auc_score_test = roc_auc_score(y_test==1, pred_test)\n",
    "    training_accuracy = accuracy_score(y_train, pred_train)\n",
    "    test_accuracy = accuracy_score(y_test, pred_test)\n",
    "    mlflow.log_metric(\"roc_auc_score_train\",roc_auc_score_train)    #B\n",
    "    print(f'Roc Auc Score train: {roc_auc_score_train}  \\n')\n",
    "    mlflow.log_metric(\"roc_auc_score_test\",roc_auc_score_test)\n",
    "    print(f'Roc Auc Score test: {roc_auc_score_test}  \\n')\n",
    "    mlflow.log_metric(\"training_accuracy\",training_accuracy)\n",
    "    print(f'Accuracy train : {training_accuracy}')\n",
    "    mlflow.log_metric(\"test_accuracy\",test_accuracy)\n",
    "    print(f'Accuracy test : {test_accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLFlow Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow import MlflowClient\n",
    "\n",
    "mlflow_client = MlflowClient()\n",
    "experiment_name = \"income-classifier\"\n",
    "experiment = mlflow_client.get_experiment_by_name(experiment_name)\n",
    "run_object = mlflow_client.search_runs(experiment_ids=experiment.experiment_id,filter_string=\"metrics.roc_auc_score_test > 0.8\",max_results=1,order_by=[\"metrics.roc_auc_score_test DESC\"])[0]\n",
    "model_uri = f\"runs:/{run_object.info.run_id}/{experiment_name}\"\n",
    "mlflow.register_model(model_uri, \"random-forest-classifier\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
